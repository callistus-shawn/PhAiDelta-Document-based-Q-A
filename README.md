### This project is a Retrieval-Augmented Generation (RAG) web application built using FastAPI. It allows users to upload documents (such as PDFs or text files), which are then chunked, embedded using Sentence Transformers, and stored in a vector database for efficient semantic search. When a user submits a question, the system retrieves the most relevant text chunks from the uploaded documents using similarity search and sends them to a Large Language Model (LLM) (e.g., OpenAI or Gemini) to generate context-aware answers. The architecture is modular, with clear separation of concerns across routing, embedding, querying, and utility modules. Key tools and libraries used include FastAPI (web framework), Pydantic (for data validation), SentenceTransformers (for generating embeddings), FAISS or similar vector DBs (for similarity search), and Uvicorn (ASGI server). The design ensures scalability, fast response times, and adaptability for various document-question answering use cases.

### üóÇÔ∏è Project Files Description

### üìÅ `fileapi/` ‚Äì Main FastAPI Application

| File         | Description |
|--------------|-------------|
| `app.py`     | Initializes the FastAPI app, mounts static files, and includes API routers. Sets up the main application context. |
| `main.py`    | Entry point for starting the FastAPI server. Imports the `app` instance from `app.py` and runs with Uvicorn. |
| `route.py`   | Central routing module where all API endpoints are declared (e.g., file upload, query handling). Uses FastAPI's `APIRouter`. |
| `model.py`   | Defines Pydantic data models used for request/response validation (e.g., handling input questions and file metadata). |


---

### üìÅ `fileapi/helper/` ‚Äì Utility Modules

| File       | Description |
|------------|-------------|
| `chunk.py` | Breaks large documents into smaller overlapping text chunks, which are critical for effective embedding and retrieval. |
| `db.py`    | Handles operations on the vector store: saving/loading embeddings, and performing similarity search based on embeddings. |

---

### üìÅ `fileapi/rag/` ‚Äì RAG Logic (Retrieval-Augmented Generation)

| File           | Description |
|----------------|-------------|
| `function.py`  | **Core RAG engine**: Handles embedding of text using Sentence Transformers, stores embeddings into the vector DB, retrieves top-k relevant chunks for a query, and communicates with the LLM for generating final answers. Integrates logic from both `upload.py` and `question.py`. |

---
